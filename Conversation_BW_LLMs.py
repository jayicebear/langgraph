from typing import List, Dict
from langchain_core import LangGraph
from langchain.chat_models import ChatOpenAI

# Define the State class that will hold information exchanged between agents (LLMs)
class State(Dict):
    messages: List[str]  # List to hold messages exchanged between LLMs
    current_response: str = ""   # Response generated by the current LLM

# Define LLMs (A and B) as separate nodes
llm_a = ChatOpenAI(model="gpt-4o-mini")
llm_b = ChatOpenAI(model="gpt-4o-mini")

# Define the function for LLM A (responds based on state and messages)
def llm_a_node(state: State) -> State:
    # LLM A processes the current state and responds
    response = llm_a.invoke({"messages": state["messages"]})
    state["current_response"] = response["messages"]
    state["messages"].append(f"LLM A: {state['current_response']}")
    return state

# Define the function for LLM B (responds based on state and messages)
def llm_b_node(state: State) -> State:
    # LLM B processes the current state and responds
    response = llm_b.invoke({"messages": state["messages"]})
    state["current_response"] = response["messages"]
    state["messages"].append(f"LLM B: {state['current_response']}")
    return state

# Create a graph builder using LangGraph
graph_builder = LangGraph(State)

# Add nodes to the graph (LLM A and LLM B)
graph_builder.add_node("llm_a", llm_a_node)
graph_builder.add_node("llm_b", llm_b_node)

# Define edges between nodes (the flow of the conversation between LLM A and B)
START = "_start_"
END = "_end_"

# Add edges (from start to LLM A, then from LLM A to LLM B, then back to LLM A, and finally to end)
graph_builder.add_edge(START, "llm_a")
graph_builder.add_edge("llm_a", "llm_b")
graph_builder.add_edge("llm_b", "llm_a")
graph_builder.add_edge("llm_a", END)

# Compile the graph
graph = graph_builder.compile()

# Initialize the state with an initial message
initial_state = State(messages=["Hello, LLM B!"])

# Set the entry point to start processing from the "START" node
graph_builder.set_entry_point(START)

# Run the graph for the conversation
current_state = initial_state
while True:
    current_node = graph_builder.get_current_node()
    if current_node == END:
        break
    current_state = graph_builder.run_node(current_node, current_state)
    graph_builder.move_to_next_node(current_state)

# Output the final state, including the updated messages
print(f"Final Conversation: {current_state['messages']}")
